{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71de4558",
   "metadata": {},
   "source": [
    "# Interpreter\n",
    "\n",
    "> Converting expressions into OOP structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db628c1",
   "metadata": {},
   "source": [
    "We will build our own custom interpreter in this lesson. We will not be building something like a full Python interpreter, but rather something smaller that shows the basics.\n",
    "\n",
    "Interpreters do their thing with 2 separate processes:\n",
    "* **Lexing**: converting a string into separate lexical tokens\n",
    "* **Parsing**: interpreting a sequence of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247d458",
   "metadata": {},
   "source": [
    "## Lexing\n",
    "\n",
    "We will begin with **lexing**: we want to convert the string `(13+4)-(12+1)` into its tokens:\n",
    "1. We want a method (we will call it `calc`) that takes a string and converts it into an arithmetic operation represented by tokens.\n",
    "2. Within this method, we will **lex** the input and convert it into **tokens**.\n",
    "3. We will need to define what a **token** is as well as the `lex` method.\n",
    "\n",
    "This translates to this skeleton code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b935bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    pass # we'll implement this later\n",
    "\n",
    "def lex(input):\n",
    "    pass # we'll implement this later\n",
    "\n",
    "def calc(input):\n",
    "    tokens = lex(input)\n",
    "    \n",
    "calc('(13+4)-(12+1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2365dc2",
   "metadata": {},
   "source": [
    "Let's implement our `Token` class. A token is any of the symbols that we can see in our arithmetic expression, so we will need to define every single one of those. Here's an implementation with enums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2302f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "class Token:\n",
    "    class Type(Enum): # the types of tokens that we can see in our expression\n",
    "        INTEGER = auto()\n",
    "        PLUS = auto()\n",
    "        MINUS = auto()\n",
    "        LPAREN = auto()\n",
    "        RPAREN = auto()\n",
    "\n",
    "    def __init__(self, type, text):\n",
    "        \"\"\"We keep both the type and the original string so that we can print the token\"\"\"\n",
    "        self.type = type\n",
    "        self.text = text\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'`{self.text}`' # The backwards quotes `` are useful for delimiting characters such as white spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890f125",
   "metadata": {},
   "source": [
    "Now we will build our lexing process. We will create a `lex` function that will build up an array of tokens based on our string input, so we will have to loop through our string, convert each character into a token sequentially and append the tokens to the array: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8b1d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex(input):\n",
    "    result = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(input):\n",
    "        if input[i] == '+':\n",
    "            result.append(Token(Token.Type.PLUS, '+'))\n",
    "        elif input[i] == '-':\n",
    "            result.append(Token(Token.Type.MINUS, '-'))\n",
    "        elif input[i] == '(':\n",
    "            result.append(Token(Token.Type.LPAREN, '('))\n",
    "        elif input[i] == ')':\n",
    "            result.append(Token(Token.Type.RPAREN, ')'))\n",
    "        else:  # must be a number\n",
    "            digits = [input[i]]\n",
    "            for j in range(i + 1, len(input)):\n",
    "                if input[j].isdigit():\n",
    "                    digits.append(input[j])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    result.append(Token(Token.Type.INTEGER,\n",
    "                                        ''.join(digits)))\n",
    "                    break\n",
    "        i += 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a59cda",
   "metadata": {},
   "source": [
    "The loop is imple enough for non-digits: we detect the token, append it to the array, increase the counter and go to the next character.\n",
    "\n",
    "When we detect a digit, we can't follow the same strategy because the number twelve is a single token rather than a combination of two tokens (`12` is not the same as `1` and `2`), so what we do instead is create a secondary array where we append each digit that we detect until we detect a non-digit, then we create a single token for the detected number in the array.\n",
    "\n",
    "Let's rerun our `calc` definition and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c3fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`(` `13` `+` `4` `)` `-` `(` `12` `+` `1` `)`\n"
     ]
    }
   ],
   "source": [
    "def calc(input):\n",
    "    tokens = lex(input)\n",
    "    print(' '.join(map(str, tokens))) # we add spaces so that we can clearly tell the tokens apart\n",
    "    \n",
    "calc('(13+4)-(12+1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90271081",
   "metadata": {},
   "source": [
    "We can clearly see that each token has been properly detected, including multi-digit numbers.\n",
    "\n",
    "Let's move on to **parsing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937dbc46",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "**Parsing** consists of turning a sequence of tokens into an **expression tree**, which we can subsequently traverse with the **visitor pattern** in order to either print or evaluate the expression.\n",
    "\n",
    "We will create a `parse` function that will return this expression tree and we will add it to `calc`, but first, we need to define what the expression tree is made of. We will define 2 elements that can go in our tree: an `Integer` and a `BinaryExpression`, an expression with a left part and a right part; the expression can be either a subtraction or an addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b1c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integer:\n",
    "    \"\"\"We simply store the value of the integer\"\"\"\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        \n",
    "class BinaryExpression:\n",
    "    class Type(Enum):\n",
    "        ADDITION = auto()\n",
    "        SUBTRACTION = auto()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.type = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    @property # getter\n",
    "    def value(self):\n",
    "        if self.type == self.Type.ADDITION:\n",
    "            return self.left.value + self.right.value\n",
    "        elif self.type == self.Type.SUBTRACTION:\n",
    "            return self.left.value - self.right.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8dd4f",
   "metadata": {},
   "source": [
    "We define a *property* in `BinaryExpression` that calculates the value of the expression based on its left and right sides. In other words, it **evaluates** the expression.\n",
    "\n",
    "We will now define a `parse` function that will take a list of tokens as input. We will assume that the top level expression that we're going to build is always going to be a binary expression, for simplicity's sake. In other words: the return of this method will be of type `BinaryExpression`. The function will loop through the token list and decide what to do depending on the token type encountered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f632bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(tokens):\n",
    "    result = BinaryExpression()\n",
    "    have_lhs = False # lhs = left hand side\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        token = tokens[i]\n",
    "\n",
    "        if token.type == Token.Type.INTEGER:\n",
    "            integer = Integer(int(token.text))\n",
    "            if not have_lhs:\n",
    "                result.left = integer\n",
    "                have_lhs = True\n",
    "            else:\n",
    "                result.right = integer\n",
    "        elif token.type == Token.Type.PLUS:\n",
    "            result.type = BinaryExpression.Type.ADDITION\n",
    "        elif token.type == Token.Type.MINUS:\n",
    "            result.type = BinaryExpression.Type.SUBTRACTION\n",
    "        elif token.type == Token.Type.LPAREN:  # note: no if for RPAREN\n",
    "            j = i\n",
    "            while j < len(tokens):\n",
    "                if tokens[j].type == Token.Type.RPAREN:\n",
    "                    break\n",
    "                j += 1\n",
    "            # preprocess subexpression\n",
    "            subexpression = tokens[i + 1:j]\n",
    "            element = parse(subexpression)\n",
    "            if not have_lhs:\n",
    "                result.left = element\n",
    "                have_lhs = True\n",
    "            else:\n",
    "                result.right = element\n",
    "            i = j  # we skip the subexpression and proceed to the next token\n",
    "        i += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2a5fb",
   "metadata": {},
   "source": [
    "Here's what's going on in the loop:\n",
    "\n",
    "1. If we encounter an integer, we need to figure out whether it's the left or right side of the expression; we use a boolean flag for this.\n",
    "2. If we encounter a plus or minus sign, we assign the expression type.\n",
    "3. If we encounter an opening parenthesis, we need to detect the subexpression within, so we create another loop to detect all the tokens until we find the closing parenthesis and we recursively call `parse` on the subexpression; we then assign the subexpression to the left or right side according to the flag.\n",
    "\n",
    "Let's expand `calc` with our parsing funtion and see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fba5818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`(` `13` `+` `4` `)` `-` `(` `12` `+` `1` `)`\n",
      "(13+4)-(12+1) = 4\n"
     ]
    }
   ],
   "source": [
    "def calc(input):\n",
    "    # lexing\n",
    "    tokens = lex(input)\n",
    "    print(' '.join(map(str, tokens)))\n",
    "    \n",
    "    # parsing\n",
    "    parsed = parse(tokens)\n",
    "    print(f'{input} = {parsed.value}')\n",
    "    \n",
    "calc('(13+4)-(12+1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747860c",
   "metadata": {},
   "source": [
    "It works! We have successfully interpreted a string into an actual arithmetic expression.\n",
    "\n",
    "> This implementation has many limitations: it does not support n-ary expressions such as `1+2+(3-4)` and it does not parse deep parenthesis nesting such as `(13+(2+2))-((6+6)+1)`. This is just a simple example for illustration purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
